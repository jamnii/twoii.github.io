[
  
  {
    "title": "CGI、FastCGI、PHP-FPM、Reactor、I/O复用模型",
    "url": "/posts/php-fpm-other/",
    "categories": "CGI",
    "tags": "CGI, PHP-FPM",
    "date": "2021-02-25 00:00:00 +0800",
    





    "snippet": "CGI、FastCGI、PHP-FPM、Reactor、I/O复用模型CGIcommon gateway interface (公共网关接口)  请求模式:        Web Brower(浏览器) —-(通过http协议传输)—-&amp;gt; Http Server(服务器nginx/apache) —–&amp;gt; CGI Program —–&amp;gt; Db  Server 与 CGI 通过 STDIN/STDOUT(标准的输入/输出)进行数据传递  nginx(动态加载模块) apache(指定加载模块)CGI工作原理  每当客户请求CGI的时候，WEB服务器就请求操作系统生成一个新的CGI解释器进程(如php-cgi.exe)，  CGI 的一个进程则处理完一个请求后退出，下一个请求来时再创建新进程。  当然，这样在访问量很少没有并发的情况也行。可是当访问量增大，并发存在，这种方式就不 适合了。于是就有了fastcgi。        单个请求,多个请求重复操作                (web)                  ↓               (server)                  ↓            (CGI解释器进程)                  ↓             (处理并返回)FastCGI  像是一个常驻(long-live)型的CGI，它可以一直执行着，只要激活后，不会每次都要花费时间去fork一次（这是CGI最为人诟病的fork-and-execute 模式）。    一般情况下，FastCGI的整个工作流程是这样的：  1.Web Server启动时载入FastCGI进程管理器（IIS ISAPI或Apache Module)  2.FastCGI进程管理器自身初始化，启动多个CGI解释器进程(可见多个php-cgi)并等待来自Web Server的连接。  3.当客户端请求到达Web Server时，FastCGI进程管理器选择并连接到一个CGI解释器。 Web server将CGI环境变量和标准输入发送到FastCGI子进程php-cgi。  4.FastCGI 子进程完成处理后将标准输出和错误信息从同一连接返回Web Server。  当FastCGI子进程关闭连接时， 请求便告处理完成。  FastCGI子进程接着等待并处理来自FastCGI进程管理器(运行在Web Server中)的下一个连接。  在CGI模式中，php-cgi在此便退出了。    |           server    |---------------------------------    |  (server start)                |    |         ↓                      |    | (FastCGI进程管理器)          ↙   ←  (请求来了)   ←      (web)    |         ↓  等待请求  → (接活了) → (php-cgi1接客)    | (php-cgi1,php-cgi2,php-cgi3,..)|    ↓    |--------------------------------|(处理完成返回)    |         ↑ 其它羡慕了                  ↓    |         ←   (干活真开心:)  ←     (php-cgi1回来了)php-fpmPHP内置的一种fast-cgi:PHP-FPM 即 PHP-Fastcgi Process Manager.PHP-FPM 是 FastCGI 的实现，并提供了进程管理的功能。进程包含 master 进程和 worker 进程两种进程。master 进程只有一个，负责监听端口，接收来自 Web Server 的请求，而 worker 进程则一般有多个(具体数量根据实际需要配置)，每个进程内部都嵌入了一个 PHP 解释器，是 PHP 代码真正执行的地方。Nginx和PHP-FPM的进程间通信有两种方式: 一种是TCP、一种是UNIX Domain Socket。其中TCP是IP加端口，可以跨服务器。而UNIX Domain Socket不经过网络，只能用于Nginx跟PHP-FPM都在同一服务器的场景。PHP生命周期 PHP程序的启动              前置初始化(Apache或Nginx相关操作)              模块初始化       对应扩展 php.dll              请求初始化       $_SERVER等参数      I      frame   执行php脚本      code               I   I可以重复执行(一般为框架内容)              请求处理完成     request            I              关闭模块        close Apache:       A: php作为Apache的一个模块的启动和终止.          这次php会初始化一些必要的数据(PHP_MINIT_FUNCTION),          比如和Apache有关的,这些数据时常驻内存的!终止与之对应.       B: Apache分配一个页面请求过来的时候,php会有一次启动和终止 PHP扩展周期:      http://www.cunmou.com/phpbook/1.md      Module init、Request init、Request Shutdown、Module shutdown 四个过程      具体的执行顺序如下请求步骤Web Brower(浏览器访问) www.example.com|        |   通过http协议传输|        |    http server (服务器nginx/apache)|        |     配置解析路由到 www.example.com/index.php(根据配置加载,如果是静态文件index.html不会走这里)|        |加载 nginx 的 fast-cgi 模块 (ngx_http_fastcgi_module),配置基于(nginx.conf)|        |fast-cgi 监听 127.0.0.1:9000 地址通过 fast-cgi 协议将请求转发给 php-fpm 处理,配置基于(php-fpm.conf)|        |请求到达 127.0.0.1:9000 (接收到请求转发到php-fpm)|        |php-fpm 监听 127.0.0.1:9000可通过 php-fpm.conf 进行修改(php-fpm 是一个多进程的 fast-cgi 管理程序)|        |php-fpm 接收到请求，启用 worker 进程处理请求(worker进程 会抢占式的获得 cgi 请求进行处理)|        |    PHP解释器 处理请求|        |     处理详解        ||处理过程:等待 php 脚本的解析,等待业务处理的结果返回,|       完成后回收子进程,这整个的过程是阻塞等待的.|处理弊端:也就意味着 php-fpm 的进程数有多少能处理的请求也就是多少,|       假设 php-fpm 有 200 个 worker进程,一个请求将耗费 1 秒的时间,|       那么简单的来说整个服务器理论上最多可以处理的请求也就是 200 个,QPS 即为 200/s.|       在高并发的场景下，这样的性能往往是不够的，|       尽管可以利用 nginx 作为负载均衡配合多台 php-fpm 服务器来提供服务，|       但由于 php-fpm 的阻塞等待的工作模型，一个请求会占用至少一个 MySQL 连接，|       多节点高并发下会产生大量的 MySQL 连接，而 MySQL 的最大连接数默认值为 100，尽管可以修改，|       但显而易见该模式没法很好的应对高并发的场景        ||   PHP生命周期(宏都是在walu.c中)|              前置初始化(Apache或Nginx相关操作)|              模块初始化       对应扩展 php.dll|              请求初始化       $_SERVER等参数    [|      frame   执行php脚本      code                可以重复执行(一般为框架内容)|              请求处理完成      request          ]|              关闭模块         close|       |    其它内容|       |nginx 将结果通过 http 返回给浏览器PHP-FPM + Nginx  FPM 是 Master/Worker 模式，启动一个 Master 进程监听来自 Nginx 的请求，再 fork 多个 Worker 进程处理请求。  每个 Worker 进程只能处理一个请求，单一进程的生命周期参照 PHP生命周期。  多进程模型是依赖进程数来解决并发问题，一个进程只能处理一个连接，当启动大量进程，进程调度消耗可能占 CPU 的百分之几十甚至 100%，比如 C10K 问题，多进程模型就力不从心了。Swoole运行图：  搜索所得，并非自己总结。  Swoole 采用的也是 Master/Worker 模式，不同的是 Master 进程有多个 Reactor 线程，Master 只是一个事件发生器，负责监听 Socket 句柄的事件变化。  Worker 以多进程的方式运行，接收来自 Reactor 线程的请求，并执行回调函数（PHP 编写的）。  启动 Master 进程的流程大致是：            初始化模块。              初始化请求。因为 swoole 需要通过 cli 的方式运行，所以初始化请求时，不会初始化 PHP 的全局变量，如 $_SERVER, $_POST, $_GET 等。              执行 PHP 脚本。包括词法、语法分析，变量、函数、类的初始化等，Master 进入监听状态，并不会结束进程。        Swoole 加速的原理            由 Reactor（epoll 的 IO 复用方式）负责监听 Socket 句柄的事件变化，解决高并发问题。              通过内存常驻的方式节省 PHP 代码初始化的时间，在使用笨重的框架时，用 swoole 加速效果是非常明显的。        对比不同  PHP-FPM  1. Master 主进程 / Worker 多进程模式。  2. 启动 Master，通过 FastCGI 协议监听来自 Nginx 传输的请求。  3. 每个 Worker 进程只对应一个连接，用于执行完整的 PHP 代码。  4. PHP 代码执行完毕，占用的内存会全部销毁，下一次请求需要重新再进行初始化等各种繁琐的操作。  5. 只用于 HTTP Server。Swoole  1. Master 主进程（由多个 Reactor 线程组成）/ Worker 多进程（或多线程）模式  2. 启动 Master，初始化 PHP 代码，由 Reactor 监听 Socket 句柄的事件变化。  3. Reactor 主线程负责子多线程的均衡问题，     Manager 进程管理 Worker 多进程，包括 TaskWorker 的进程。  4. 每个 Worker 接受来自 Reactor 的请求，只需要执行回调函数部分的 PHP 代码。  5. 只在 Master 启动时执行一遍 PHP 初始化代码，Master 进入监听状态，并不会结束进程。  6. 不仅可以用于 HTTP Server，还可以建立 TCP 连接、WebSocket 连接。  I/O多路复用机制I/O多路复用 : 每个进程/线程同时处理 多个连接(I/O多路复用)利用epoll来实现IO多路复用,将连接信息和事件放到队列中,依次放到文件事件分派器,事件分派器将事件分发给事件处理器.c10k：https://www.jianshu.com/p/ba7fa25d3590用户A-Z -&amp;gt; I/O多路复用(s0,s1,s2,s3) -依次放到-&amp;gt; 文件事件分派器 -&amp;gt; 事件处理器(连接应答处理器1...)  c10k(一瞬间1w请求)    早期的一个TCP请求,就会创建一个进程(或线程),而进程属于操作系统,是非常昂贵的资源,并且有数量限制.创建的进程线程多了,数据拷贝频繁（缓存I/O、内核将数据拷贝到用户进程空间、阻塞）,进程/线程上下文切换消耗大, 导致操作系统崩溃,这就是C10K问题的本质！        简单说下epoll(基于Linux)    支持一个进程打开大数目的socket描述符(fd)只对发生变化的文件句柄感兴趣,工作机制类似于&quot;事件&quot;通过 epoll_create 创建 epoll对象,linux内核会创建一个eventpoll结构体( 重要的两个成员:  红黑树的根节点: 这棵树中存储着所有添加到epoll中的事件，也就是这个epoll监控的事件。  双向链表rdllist: 保存着将要通过epoll_wait返回给用户的、满足条件的事件。)通过 epoll_ctl 注册文件描述符fd,一旦该fd就绪,内核就会采用类似 callback 的回调机制来激活该fd,epoll_wait 便可以收到通知, 并通知应用程序.            简单示例    I/O多路复用(又被称为“事件驱动”)one, two, ..., six 和 ser 进行聊天1.逐个询问是否有聊天信息,如果 one 有,那 ser 处理 one 的信息,其它的就卡住.(阻塞)2.ser 创建多个分身,即为每个用户创建个进程或者线程.(消耗过大)3.one, two 主动告诉 ser 有信息, ser 依次进行处理, 然后等待其它人的通知.(非阻塞模式)                                          tcp(ser)one(fd)(client socket)  - 注册入epoll -&amp;gt;  建立callback event    -&amp;gt;  有变化(fd) -&amp;gt; epoll收到通知 -&amp;gt; 告诉tcp进行处理two(fd)(client socket)  - 注册入epoll -&amp;gt;  建立callback event    -&amp;gt;  非阻塞six(fd)(client socket)  - 注册入epoll -&amp;gt;  建立callback event    -&amp;gt;  非阻塞      "
  },
  
  {
    "title": "MySQL Transaction",
    "url": "/posts/mysql-transaction/",
    "categories": "MySQL",
    "tags": "transaction",
    "date": "2021-02-20 16:42:00 +0800",
    





    "snippet": "MySQL 事务主要用于处理操作量大，复杂度高的数据。1. 基础介绍2. ACIDAtomicity原子性: 一个事务被视为一个不可分割的最小工作单元 一个事务中的所有操作，要么全部完成，要么全部不完成，不会在中间某个环节结束。事务在执行过程中发生错误，会被回滚到事务开始前的状态，就像这个事务从来没有执行过一样。原子性关注状态，要么全部成功，要么全部失败，不存在部分成功的状态Consistency一致性: 在事务开始之前和事务结束以后，数据库数据的一致性约束没有被破坏。 保证在一个事务中的多次操作的数据中间状态,对其他事务不可见的。因为这些中间状态，是一个过渡状态，与事务的开始状态和事务的结束状态是不一致的，一致性关注数据的可见性，中间状态的数据对外部不可见，只有最初状态和最终状态的数据对外可见。(memberA 向 memberB 转 100,在其它事物看来,要么 memberA 减少了, 要么 memberB 增加了)不会看到 memberA 减少了, memberB还没有加的情况,这个属于中间状态)与 `Atomicity` 的区别: 未提交读的隔离级别下是事务内部操作是可见的，明显违背了一致性。Isolation隔离性: 数据库允许多个并发事务同时对数据进行读写和修改的能力。 隔离性可以防止多个事务并发执行时由于交叉执行而导致数据的不一致。Durability持久性: 事务处理结束后，对数据的修改就是永久的，即便系统故障也不会丢失。3. 隔离级别针对多个事物的数据处理，不同的隔离级别对数据会有不同的影响。      设置事物隔离级别    show variables like &quot;%isolation%&quot;;&quot;read uncommitted, read committed, repeatable read, serializable&quot;set session transaction isolation level repeatable read;            锁测试    关闭自动提交#show variables like &quot;autocommit&quot;;set session autocommit=0;#开始事物start transaction;#sqlcommit;#查看事务与锁信息show engine innodb status;#分析sql,死锁:1.没走行锁,索引失效,全表扫描explain sql;            autocommit              自动提交: 如果 autocommit 开启，则每个SQL语句将自己形成一个事务。                  非自动提交: 需要执行多语句事务 START TRANSACTION 或 BEGIN 语句，并用它结束 COMMIT或 ROLLBACK 声明。      Read-Uncommitted读-未提交，有脏读数据: name = test， A事物更新 name = test2，同时B事物开启，B执行查询name = test2，若A回滚，实际数据为 name = test，而B却返回了 name = test2，这就称之为脏读.Read(B事物读取)-Uncommitted(A事物未提交成功的操作[更新]数据): 有脏读。TimeLine                   原数据 name = testA事物 ↓start ↓执行更新 ↓name = test2    此时     B事物 → start → 查询 -&amp;gt; name = test2 ↓                                                  ↓回滚                                          返回(name = test2)A事物并没有修改成功，但B事物已经返回 name = test2，出现了脏读Read-Committed读-已提交,不可重复读一个事务只能读到另一个事务修改的已经提交了事务的数据。A隐式提交了事物，B查询 name = test2，这是没有问题的。但B还没有结束，A中执行更新 name = test3，B执行查询 name = test3，这种称之为 不可重复读。Read(B事物读取)-Committed(A事物提交成功的操作[更新]数据): 不可重复读，Commit 后数据发生改变。TimeLine                原数据 name = testB事物                    A事物 ↓                        ↓start                   start → 执行 name = test2 → commit.(At1) ↓查询(name = test2) ↓其它操作                 A事物 ↓                       ↓其它操作                 start → 执行 name = test3 → commit.(At2) ↓查询(name = test3) ↓提交在B事物的时间线中，A事物对数据进行了两次操作，B事物进行了两次查询，但只能读取到操作后的数据。数据会跟着事物修改而改变。Tips:1.在RC隔离级别下并不是不会出现死锁，只是出现几率比RR低而已！2.在RC隔离级别下，条件列未命中索引只会锁行！3.在RC隔离级别下，半一致性读(semi-consistent)特性增加了update操作的并发性！减少了更新同一行记录时的冲突，减少锁等待。4.半一致性读: 所谓半一致性读就是，一个update语句，如果读到一行已经加锁的记录，此时InnoDB返回记录最近提交的版本，由MySQL上层判断此版本是否满足update的where条件。若满足(需要更新)，则MySQL会重新发起一次读操作，此时会读取行的最新版本(并加锁)！Repeatable-Read可重复读第一次读取的数据，即使别的事务修改的这个值，这个事务再读取这条数据的时候还是和第一次获取的一样，不会随着别的事务的修改而改变。原始数据 name = test， 开启A、B两个事物， A修改 name = test2，同时B事物查询 name = test,不管事物A是否提交，在B事物没有提交之前，这条数据对B来说一直都是没有发生改变的，是可以重复的被读到。TimeLine                原数据 name = testB事物                    A事物 ↓                        ↓start                   start ↓                        ↓查询(name = test)       修改(name = test2)  → 提交 ↓再次查询(name = test) ↓查询(name = test) ↓提交在B事物的时间线中，不管A事物执行什么操作，或者执行回滚或提交。B事物的值始终为第一次获取的值。数据不会跟着事物修改而改变。Tips:1.在RR隔离级别下，存在间隙锁，导致出现死锁的几率比RC大的多！2.在RR隔离级别下，条件列未命中索引会锁表！Serializable串行化只能进行读-读并发。只要有一个事务操作一条记录的写，那么其他要访问这条记录的事务都得等着一般没人用串行化，性能比较低，常用的是已提交读和可重复读。"
  },
  
  {
    "title": "MySql Locks",
    "url": "/posts/mysql-locks/",
    "categories": "MySQL",
    "tags": "MySQL, Lock",
    "date": "2021-02-06 00:00:00 +0800",
    





    "snippet": "锁是计算机协调多个进程或线程并发访问某一资源的机制。锁保证数据并发访问的一致性、有效性；锁冲突也是影响数据库并发访问性能的一个重要因素。锁是Mysql在服务器层和存储引擎层的的并发控制。加锁是消耗资源的，锁的各种操作，包括获得锁、检测锁是否已解除、释放锁等。锁的类型这里主要介绍表锁和行锁。表锁表锁由 MySQL Server 实现，一般在执行 DDL(Data Definition Language) 语句时会对整个表进行加锁，比如说 ALTER,UPDATE TABLE 等操作。在执行 SQL 语句时，也可以明确指定对某个表进行加锁。表锁使用的是一次性锁技术,只能访问加锁的表，不能访问其他表，直到最后通过 unlock tables 释放所有表锁|-------| read  ||---------------------------------------------------------------------------------------------|`lock table test read;` #为test表设置读锁[read|write]||`select * from test where id = 1;` #成功||#失败,Table &#39;test_2&#39; was not locked with LOCK TABLES,没有读表锁|`select * from test_2 where id = 2;`||#Table &#39;test&#39; was locked with a READ lock and can&#39;t be updated|`update test  set name = &#39;one&#39; where id = 1;` # 失败，未提前获得test的写表锁||`unlock talbes;`#解锁|`lock table test_2 read;`#此时会释放 test 的读表锁,或者 start transaction | begin 也会释放之前的锁|---------------------------------------------------------------------------------------------|-------| write ||---------------------------------------------------------------------------------------------|`lock table test write;` #为test表设置读锁[read|write]||`select * from test where id = 1;` #成功||#失败,Table &#39;test_2&#39; was not locked with LOCK TABLES,没有读表锁|`select * from test_2 where id = 2;`||`update test  set name = &#39;one&#39; where id = 1;` # 成功||`unlock tables;`#解锁|---------------------------------------------------------------------------------------------行锁目前主要针对与InnoDB,行锁的机制是根据索引来的.索引分为聚簇索引和非聚簇索引.聚簇索引(主键索引加锁)非聚簇索引(普通索引加锁,主键索引加锁)范围更新加锁(内部执行:获取满足条数的第一条数据-&amp;gt;返回并加锁-&amp;gt;更新记录-&amp;gt;更新成功-&amp;gt;重复)行锁的模式行锁的模式有很多，这里主要介绍 共享锁|读锁|S锁、排他锁|写锁|X锁、意向锁、自增锁 等。共享锁 读写锁-&amp;gt;读锁读锁，又称共享锁（Share locks，简称 S 锁），加了读锁的记录，所有的事务都可以读取，但是不能修改，并且可同时有多个事务对记录加读锁。                ts1                 ↓ ts2  →   [(one row data),SL]     ←   ts3               (ts0)排他锁 读写锁-&amp;gt;写锁写锁，又称排他锁（Exclusive locks，简称 X 锁），或独占锁，对记录加了排他锁之后，只有拥有该锁的事务可以读取和修改，其他事务都不可以读取和修改，并且同一时间只能有一个事务加写锁。                ts1                 ↓                 ↑             我只属于ts0 ts2  →←   [(one row data),XL]     →←   ts3               (ts0)意向锁(intention:意向)由于表锁和行锁虽然锁定范围不同，但是会相互冲突。所以当你要加表锁时，势必要先遍历该表的所有记录，判断是否加有排他锁。这种遍历检查的方式显然是一种低效的方式，MySQL 引入了意向锁，来检测表锁和行锁的冲突。意向锁也是表级锁，也可分为读意向锁（IS 锁）和写意向锁（IX 锁）。当事务要在记录上加上读锁或写锁时，要首先在表上加上意向锁。这样判断表中是否有记录加锁就很简单了，只要看下表上是否有意向锁就行了。意向锁之间是不会产生冲突的，也不和 AUTO_INC 表锁冲突，它只会阻塞表级读锁或表级写锁，另外，意向锁也不会和行锁冲突，行锁只会和行锁冲突。自增锁(auto increment)AUTOINC 锁又叫自增锁（一般简写成 AI 锁），是一种表锁，当表中有自增列（AUTOINCREMENT）时出现。当插入表中有自增列时，数据库需要自动生成自增值，它会先为该表加 AUTOINC 表锁，阻塞其他事务的插入操作，这样保证生成的自增值肯定是唯一的。AUTOINC 锁具有如下特点：    AUTO_INC 锁互不兼容，也就是说同一张表同时只允许有一个自增锁；    自增值一旦分配了就会 +1，如果事务回滚，自增值也不会减回去，所以自增值可能会出现中断的情况。显然，AUTOINC 表锁会导致并发插入的效率降低，为了提高插入的并发性，MySQL 从 5.1.22 版本开始，引入了一种可选的轻量级锁（mutex）机制来代替 AUTOINC 锁，可以通过参数 innodb autoinc lock mode 来灵活控制分配自增值时的并发策略。行锁总结意向锁之间互不冲突；S 锁只和 S/IS 锁兼容，和其他锁都冲突；X 锁和其他所有锁都冲突；AI 锁只和意向锁兼容；行锁的类型根据锁的粒度可以把锁细分为表锁和行锁，行锁根据场景的不同又可以进一步细分，依次为 Next-Key Lock，Gap Lock 间隙锁，Record Lock 记录锁和插入意向 GAP 锁。不同的锁锁定的位置是不同的，比如说记录锁只锁住对应的记录，而间隙锁锁住记录和记录之间的间隔，Next-Key Lock 则所属记录和记录之前的间隙。不同类型锁的锁定范围大致如下                      Next-Key Lock                 ↑                   ↑                 (Gap Lock 1)         (Gap Lock 2)         (Gap Lock 3)(-∞)     (Key=3)              (Key=10)            (Key=20)             (+∞)                              ↑      ↑            ↑      ↑                           Record Lock 1        Record Lock 2记录锁(Record Lock)记录锁是最简单的行锁。InnoDB 加锁原理中的锁就是记录锁，只锁住 id = 1 或者 field = &#39;value&#39; 这一条记录。当 SQL 语句无法使用索引时，会进行全表扫描，这个时候 MySQL 会给整张表的所有数据行加记录锁，再由 MySQL Server 层进行过滤。但是，在 MySQL Server 层进行过滤的时候，如果发现不满足 WHERE 条件，会释放对应记录的锁。这样做，保证了最后只会持有满足条件记录上的锁，但是每条记录的加锁操作还是不能省略的。所以更新操作必须要根据索引进行操作，没有索引时，不仅会消耗大量的锁资源，增加数据库的开销，还会极大的降低了数据库的并发性能。间隙锁如果 Key = 17 这条记录不存在，这个 SQL 语句还会加锁吗？在 RC 隔离级别不会加任何锁，在 RR 隔离级别会在 Key = 17 前后两个索引之间加上间隙锁。间隙锁是一种加在两个索引之间的锁，或者加在第一个索引之前，或最后一个索引之后的间隙。这个间隙可以跨一个索引记录，多个索引记录，甚至是空的。使用间隙锁可以防止其他事务在这个范围内插入或修改记录，保证两次读取这个范围内的记录不会变，从而不会出现幻读现象。值得注意的是，间隙锁和间隙锁之间是互不冲突的，间隙锁唯一的作用就是为了防止其他事务的插入，所以加间隙 S 锁和加间隙 X 锁没有任何区别。Next-Key 锁Next-key锁是记录锁和间隙锁的组合，它指的是加在某条记录以及这条记录前面间隙上的锁参考 Key = 10 上的 Next-Key Lock,(-∞,3],(3,10],(10,20],(20,+∞)通常用这种左开右闭区间来表示 Next-key 锁，其中，圆括号表示不包含该记录，方括号表示包含该记录RR级别下才有插入意向锁插入意向锁是一种特殊的间隙锁（简写成 II GAP）表示插入的意向，只有在 INSERT 的时候才会有这个锁。注意，这个锁虽然也叫意向锁，但是和上面介绍的表级意向锁是两个完全不同的概念，不要搞混了。插入意向锁和插入意向锁之间互不冲突，所以可以在同一个间隙中有多个事务同时插入不同索引的记录。譬如，id = 30 和 id = 49 之间如果有两个事务要同时分别插入 id = 32 和 id = 33 是没问题的，虽然两个事务都会在 id = 30 和 id = 50 之间加上插入意向锁，但是不会冲突。插入意向锁只会和间隙锁或 Next-key 锁冲突，正如上面所说，间隙锁唯一的作用就是防止其他事务插入记录造成幻读，正是由于在执行 INSERT 语句时需要加插入意向锁，而插入意向锁和间隙锁冲突，从而阻止了插入操作的执行。总结            \\      record      gap      next-key      ii gap                  record             兼容             兼容              gap      兼容      兼容      兼容      兼容              next-key             兼容             兼容              ii gap      兼容                           其中，第一行表示已有的锁，第一列表示要加的锁。插入意向锁较为特殊，所以我们先对插入意向锁做个总结，如下：    插入意向锁不影响其他事务加其他任何锁。也就是说，一个事务已经获取了插入意向锁，对其他事务是没有任何影响的；    插入意向锁与间隙锁和 Next-key 锁冲突。也就是说，一个事务想要获取插入意向锁，      如果有其他事务已经加了间隙锁或 Next-key 锁，则会阻塞。    其他类型的锁的规则较为简单：    间隙锁不和其他锁（不包括插入意向锁）冲突；    记录锁和记录锁冲突，Next-key 锁和 Next-key 锁冲突，记录锁和 Next-key 锁冲突；页锁锁的排查  并发事务，间隙锁可能互斥          A删除不存在的记录，获取共享间隙锁；      B插入，必须获得排他间隙锁，故互斥；        并发插入相同记录，可能死锁(某一个回滚)  并发插入，可能出现间隙锁死锁(难排查)  show engine innodb status; 可以查看InnoDB的锁情况，也可以调试死锁  show status like ‘innodb_row_lock%’;查看InnoDB_row_lock的状态  show variables like ‘%lock_wait_timeout%’;Innodb Row LockInnodb_row_lock_current_waits:当前正在等待锁的数量；Innodb_row_lock_time:从系统启动到现在锁定总时间长度；Innodb_row_lock_time_avg：每次等待所花平均时间；Innodb_row_lock_time_max:从系统启动到现在等待最长的一次所花的时间长度；Innodb_row_lock_waits:系统启动到现在总共等待的次数；对于这5个状态变量，比较重要的是：Innodb_row_lock_time_avg，Innodb_row_lock_waits，Innodb_row_lock_time。死锁  复现  查看事务与锁信息  分析sql      # 设置事物隔离级别 RR  # show variables like &quot;%isolation%&quot;;  # read uncommitted, read committed, repeatable read, serializable  set session transaction isolation level repeatable read;  # 关闭自动提交  # show variables like &quot;autocommit&quot;;  set session autocommit=0;  #开始事物  start transaction;  #sql  commit;  #查看事务与锁信息  show engine innodb status;  #分析sql,死锁:1.没走行锁,索引失效,全表扫描  explain sql;      间隙锁 互斥(删除?)#设置rrset session transaction isolation level repeatable read;#表信息create table t (id int(10) primary key)engine=innodb;#初始化数据start transaction;insert into t values(1);insert into t values(3);insert into t values(10);commit;#开启区间锁，RR的隔离级别下，上例会有四个区间(-infinity, 1)(1, 3)(3, 10)(10, infinity)#实例1set session autocommit=0;start transaction;delete from t where id=5;#实例2set session autocommit=0;start transaction;insert into t values(0);insert into t values(2);insert into t values(12);insert into t values(7);#结果#实例1 删除某个区间内的一条不存在记录，获取到共享间隙锁，#会阻止其他事务 实例2 在相应的区间插入数据，因为插入需要获取排他间隙锁#实例2 插入的值：0, 2, 12都不在(3, 10)区间内，能够成功插入，而7在(3, 10)这个区间内，会阻塞。#+++#删除 id=5,5在区间(3,10)触发共享间隙锁,事物未提交,#在区间(3,10)插入id=7,需要获取排他间隙锁(防止其它事物也插入id=7),但此时存在 共享间隙锁,所以会阻塞.#验证  lock_modeshow engine innodb status;*** (1) TRANSACTION:TRANSACTION 788058, ACTIVE 28 sec starting index readmysql tables in use 1, locked 1LOCK WAIT 3 lock struct(s), heap size 360, 5 row lock(s), undo log entries 4MySQL thread id 358, OS thread handle 0x7f733c67f700, query id 9079 localhost 127.0.0.1 root updating/* ApplicationName=DataGrip 2019.2.3 */ DELETE FROM `tt`.`t` WHERE `id` = 1*** (1) WAITING FOR THIS LOCK TO BE GRANTED:RECORD LOCKS space id 261 page no 3 n bits 80 index `PRIMARY` of table `tt`.`t` trx id 788058 lock_mode  X locks rec but not gap waitingRecord lock, heap no 4 PHYSICAL RECORD: n_fields 3; compact format; info bits 00: len 4; hex 80000001; asc     ;;1: len 6; hex 0000000c0640; asc      @;;2: len 7; hex fb000001fc0144; asc       D;;#正在等待共享间隙锁的释放。#insert into t values(7);#如果 事务1 提交或者回滚， 事务2 就能够获得相应的锁，以继续执行。#如果 事务2 一直不提交， 事务2 会一直等待，直到超时，超时后会显示：#ERROR 1205 (HY000): Lock wait timeout exceeded; try restarting transaction共享排他锁死锁(插入?)#表同 间隙锁互斥# Aset session autocommit=0;start transaction;insert into t values(7);# Bset session autocommit=0;start transaction;insert into t values(7);# Cset session autocommit=0;start transaction;insert into t values(7);#结果:# 1.A先执行，插入成功，并获取id=7的排他锁；# 2.B后执行，需要进行PK校验，故需要先获取id=7的共享锁，阻塞；# 3.C后执行，也需要进行PK校验，也要先获取id=7的共享锁，也阻塞；# 如果此时，session A执行：#   rollback;# id=7排他锁释放。# 则B，C会继续进行主键校验：#   (1)B会获取到id=7共享锁，主键未互斥；#   (2)C也会获取到id=7共享锁，主键未互斥；# B和C要想插入成功，必须获得id=7的排他锁，但由于双方都已经获取到id=7的共享锁，# 它们都无法获取到彼此的排他锁，死锁就出现了。# 当然，InnoDB有死锁检测机制，B和C中的一个事务会插入成功，另一个事务会自动放弃：# ERROR 1213 (40001): Deadlock found when trying to get lock; try restarting transaction并发间隙锁的死锁(插入,删除?)#共享排他锁，在并发量插入相同记录的情况下会出现，相应的案例比较容易分析。#而并发的间隙锁死锁，是比较难定位的。#两个并发的session，其SQL执行序列如下：A：set session autocommit=0;A：start transaction;A：delete from t where id=6;         B：set session autocommit=0;         B：start transaction;         B：delete from t where id=7;A：insert into t values(5);         B：insert into t values(8);#A执行delete后，会获得(3, 10)的共享间隙锁。#B执行delete后，也会获得(3, 10)的共享间隙锁。#A执行insert后，希望获得(3, 10)的排他间隙锁，于是会阻塞。#B执行insert后，也希望获得(3, 10)的排他间隙锁，于是死锁出现。记录锁(Record Locks) : 锁定索引记录记录锁，它封锁索引记录，例如：select * from t where id=1 for update;它会在id=1的索引记录上加锁，以阻止其他事务插入，更新，删除id=1的这一行。当有主键或者索引的时候，会形成行锁。当无法命中索引或者无索引、范围、模糊时，会形成表锁。明确指定索引，若无查询数据，无锁。for update 仅适用于InnoDB，并且必须开启事务，在begin与commit之间才生效。for update锁住表或者锁住行，只允许当前事务进行操作（读写），其他事务被阻塞，直到当前事务提交或者回滚，被阻塞的事务自动执行。for update nowait 锁住表或者锁住行，只允许当前事务进行操作（读写），其他事务被拒绝，事务占据的statement连接也会被断开。需要说明的是：    select * from t where id=1;    则是快照读(SnapShot Read)，它并不加锁.间隙锁(Gap Locks) : 锁定间隔，防止间隔中被其他事务插入它封锁索引记录中的间隔，或者第一条索引记录之前的范围，又或者最后一条索引记录之后的范围。插入id=10会封锁区间，以阻止其他事务id=10的记录插入。为什么要阻止id=10的记录插入？如果能够插入成功，头一个事务执行相同的SQL语句，会发现结果集多出了一条记录，即幻影数据。间隙锁的主要目的，就是为了防止其他事务在间隔中插入数据，以导致“不可重复读”。如果把事务的隔离级别降级为读提交(Read Committed, RC)，间隙锁则会自动失效。临键锁(Next-Key Locks) : 锁定索引记录+间隔，防止幻读临键锁，是记录锁与间隙锁的组合，它的封锁范围，既包含索引记录，又包含索引区间。更具体的，临键锁会封锁索引记录本身，以及索引记录之前的区间。如果一个会话占有了索引记录R的共享/排他锁，其他会话不能立刻在R之前的区间插入新的索引记录。临键锁的主要目的，也是为了避免幻读(Phantom Read)。如果把事务的隔离级别降级为RC，临键锁则也会失效。源数据锁(metadata lock) Waiting for table metadata lockKILL 掉某些事物占用的锁，使DDL成功，然后进而不阻塞其他DML操作。设置锁超时短些 lock_wait_timeoutDML（data manipulation language）数据操纵语言：    就是我们最经常用到的 SELECT、UPDATE、INSERT、DELETE。 主要用来对数据库的数据进行一些操作DDL（data definition language）数据库定义语言：    其实就是我们在创建表的时候用到的一些sql，比如说： CREATE、ALTER、DROP、TRUNCATE等。    DDL主要是用在定义或改变表的结构，数据类型，表之间的链接和约束等初始化工作上。DQL(Data Query Language) 数据查询语言DQL：    select 相关DCL（Data Control Language）数据库控制语言：    是用来设置或更改数据库用户或角色权限的语句，包括（grant,deny,revoke等）语句。这个比较少用到锁等待超时，尝试重启事物 Lock wait timeout exceeded; try restarting transaction出现死锁应该从锁的源头进行排查，这里需要和业务逻辑相互结合进行排查。DB: information_schema(数据库相关信息)Table:innodb_trx 当前运行的所有事务innodb_locks 当前出现的锁innodb_lock_waits 锁等待的对应关系可以使用 Desc 查看表结构。通过 状态 进行排除，  kill 对应的 死锁。select * from information_schema.innodb_trx;设置锁的超时时间show variables like &#39;%lock_wait_timeout%&#39;;死锁之多事物加锁顺序不一致            事物A      事物B                  update table set value = 1 where id = 20      update table set value = 1 where id = 30              update table set value = 1 where id = 30      update table set value = 1 where id = 20      AB同时执行，A获取 id = 20 的锁，B获取 id = 30 的锁。A获取 id = 30 的锁，此时锁在B事物中，需要等待。B获取 id = 20 的锁，此时锁在A事物中，需要等待。AB同时等待彼此的锁，从而导致死锁。3.4 如何避免死锁在工作过程中偶尔会遇到死锁问题，虽然这种问题遇到的概率不大，但每次遇到的时候要想彻底弄懂其原理并找到解决方案却并不容易。其实，对于 MySQL 的 InnoDb 存储引擎来说，死锁问题是避免不了的，没有哪种解决方案可以说完全解决死锁问题，但是我们可以通过一些可控的手段，降低出现死锁的概率。如上面的案例一和案例三所示，对索引加锁顺序的不一致很可能会导致死锁，所以如果可以，尽量以相同的顺序来访问索引记录和表。在程序以批量方式处理数据的时候，如果事先对数据排序，保证每个线程按固定的顺序来处理记录，也可以大大降低出现死锁的可能；如上面的案例二所示，Gap 锁往往是程序中导致死锁的真凶，由于默认情况下 MySQL 的隔离级别是 RR，所以如果能确定幻读和不可重复读对应用的影响不大，可以考虑将隔离级别改成 RC，可以避免 Gap 锁导致的死锁；为表添加合理的索引，如果不走索引将会为表的每一行记录加锁，死锁的概率就会大大增大；我们知道 MyISAM 只支持表锁，它采用一次封锁技术来保证事务之间不会发生死锁，所以，我们也可以使用同样的思想，在事务中一次锁定所需要的所有资源，减少死锁概率；避免大事务，尽量将大事务拆成多个小事务来处理；因为大事务占用资源多，耗时长，与其他事务冲突的概率也会变高；避免在同一时间点运行多个对同一表进行读写的脚本，特别注意加锁且操作数据量比较大的语句；我们经常会有一些定时脚本，避免它们在同一时间点运行；设置锁等待超时参数：innodb_lock_wait_timeout，这个参数并不是只用来解决死锁问题，在并发访问比较高的情况下，如果大量事务因无法立即获得所需的锁而挂起，会占用大量计算机资源，造成严重性能问题，甚至拖跨数据库。我们通过设置合适的锁等待超时阈值，可以避免这种情况发生。3.5 业务分析风险提示：等待行锁注册会话快照：            id      user      host      db      command      time      state      info                  18093488      test      127.0.0.1:52505      dev_test      Execute      46      updating      UPDATE member_account_test SET account = ‘A’ , token = ‘1’ WHERE id = 354754              18093496      test      127.0.0.1:52613      dev_test      Execute      46      updating      UPDATE member_account_test SET account = ‘B’ , token = ‘1’ WHERE id = 354754              18093491      test      127.0.0.1:52534      dev_test      Execute      46      updating      UPDATE member_account_test SET account = ‘C’ , token = ‘1’ WHERE id = 354754              18093549      test      127.0.0.1:53586      dev_test      Execute      44      updating      UPDATE member_account_test SET account = ‘D’ , token = ‘1’ WHERE id = 354754              18093562      test      127.0.0.1:53780      dev_test      Execute      44      updating      UPDATE member_account_test SET account = ‘E’ , token = ‘1’ WHERE id = 354754              18093546      test      127.0.0.1:53494      dev_test      Execute      44      updating      UPDATE member_account_test SET account = ‘F’ , token = ‘1’ WHERE id = 354754              18093680      test      127.0.0.1:55578      dev_test      Execute      41      updating      UPDATE member_account_test SET account = ‘G’ , token = ‘1’ WHERE id = 354754              18093821      test      127.0.0.1:57776      dev_test      Execute      39      updating      UPDATE member_account_test SET account = ‘1’ , token = ‘1’ WHERE id = 354754              18093843      test      127.0.0.1:58234      dev_test      Execute      37      updating      UPDATE member_account_test SET account = ‘H’ , token = ‘1’ WHERE id = 354755              18093820      test      127.0.0.1:57718      dev_test      Execute      37      updating      UPDATE member_account_test SET account = ‘E’ , token = ‘1’ WHERE id = 354755              18094060      test      127.0.0.1:33288      dev_test      Execute      33      updating      UPDATE member_account_test SET account = ‘O’ , token = ‘1’ WHERE id = 354755              18094087      test      127.0.0.1:33636      dev_test      Execute      31      updating      UPDATE member_account_test SET account = ‘J’ , token = ‘1’ WHERE id = 354756              18094094      test      127.0.0.1:33786      dev_test      Execute      31      updating      UPDATE member_account_test SET account = ‘K’ , token = ‘1’ WHERE id = 354756              18094147      test      127.0.0.1:35052      dev_test      Execute      31      updating      UPDATE member_account_test SET account = ‘1’ , token = ‘1’ WHERE id = 354755              18094117      test      127.0.0.1:34122      dev_test      Execute      30      updating      UPDATE member_account_test SET account = ‘L’ , token = ‘1’ WHERE id = 354756      分析：等待行锁  354754 出现了 8 次，均为 update，每次更新的 account 都不相同。  注册逻辑为账号分配+事物。当并发量比较高的时候，单毫秒随机分配可能对应多个用户，find one、get one、one 等都会失效。  比如： 用户ID 354754 对应了 8 个用户。由于注册逻辑中包含了事物，导致多事物同时操作一条数据，sql 语句 可能会触发 锁 相关的问题，导致 cup 处理变慢，从而导致卡顿，甚至宕机。分析： Gap Lock  member_third_login_test  column：member_id(pk)，open_id  由于 member_id 来源于 member_account_test -&amp;gt; id，相对随机。  当处于事物时，会触发 Gap Lock 。"
  },
  
  {
    "title": "Getting Started",
    "url": "/posts/getting-start/",
    "categories": "Blogging, Tutorial",
    "tags": "getting started",
    "date": "2019-08-09 20:55:00 +0800",
    





    "snippet": "  Prerequisites  Installation          Creating a New Site                  Option 1. Using the Chirpy Starter          Option 2. Forking on GitHub                    Installing Dependencies        Usage          Configuration      Customing Stylesheet      Running Local Server      Deployment                  Deploy by Using Github Actions          Manually Build and Deploy                    Upgrading      PrerequisitesFollow the instructions in the Jekyll Docs to complete the installation of Ruby, RubyGems, Jekyll, and Bundler.InstallationCreating a New SiteThere are two ways to create a new repository for this theme:  Using the Chirpy Starter - Easy to upgrade, isolates irrelevant project files so you can focus on writing.  Forking on GitHub - Convenient for custom development, but difficult to upgrade. Unless you are familiar with Jekyll and are determined to tweak or contribute to this project, this approach is not recommended.Option 1. Using the Chirpy StarterCreate a new repository from the Chirpy Starter and name it &amp;lt;GH_USERNAME&amp;gt;.github.io, where GH_USERNAME represents your GitHub username.Option 2. Forking on GitHubFork Chirpy on GitHub and rename it to &amp;lt;GH_USERNAME&amp;gt;.github.io. Please note that the default branch code is in development.  If you want the site to be stable, please switch to the latest tag and start writing.And then execute:$ bash tools/init.sh  Note: If you don’t want to deploy your site on GitHub Pages, append option --no-gh at the end of the above command.The above command will:  Removes some files or directories from your repository:          .travis.yml      files under _posts      folder docs            If the option --no-gh is provided, the directory .github will be deleted. Otherwise, set up the GitHub Action workflow by removing the extension .hook of .github/workflows/pages-deploy.yml.hook, and then remove the other files and directories in the folder .github.        Removes item Gemfile.lock from .gitignore.    Creates a new commit to save the changes automatically.Installing DependenciesBefore running for the first time, go to the root directory of your site, and install dependencies as follows:$ bundleUsageConfigurationUpdate the variables of _config.yml as needed. Some of them are typical options:  url  avatar  timezone  langCustoming StylesheetIf you need to customize the stylesheet, copy the theme’s assets/css/style.scss to the same path on your Jekyll site, and then add the custom style at the end of the style file.Starting from v4.1.0, if you want to overwrite the SASS variables defined in _sass/addon/variables.scss, create a new file _sass/variables-hook.scss and assign new values to the target variable in it.Running Local ServerYou may want to preview the site contents before publishing, so just run it by:$ bundle exec jekyll sOr run the site on Docker with the following command:$ docker run -it --rm \\    --volume=&quot;$PWD:/srv/jekyll&quot; \\    -p 4000:4000 jekyll/jekyll \\    jekyll serveAfter a while, the local service will be published at http://127.0.0.1:4000.DeploymentBefore the deployment begins, check out the file _config.yml and make sure the url is configured correctly. Furthermore, if you prefer the project site and don’t use a custom domain, or you want to visit your website with a base URL on a web server other than GitHub Pages, remember to change the baseurl to your project name that starts with a slash, e.g, /project-name.Now you can choose ONE of the following methods to deploy your Jekyll site.Deploy by Using Github ActionsFor security reasons, GitHub Pages build runs on safe mode, which restricts us from using plugins to generate additional page files. Therefore, we can use GitHub Actions to build the site, store the built site files on a new branch, and use that branch as the source of the GitHub Pages service.Quickly check the files needed for GitHub Actions build:      Ensure your Jekyll site has the file .github/workflows/pages-deploy.yml. Otherwise, create a new one and fill in the contents of the sample file, and the value of the on.push.branches should be the same as your repo’s default branch name.        Ensure your Jekyll site has file tools/deploy.sh. Otherwise, copy it from here to your Jekyll site.        Furthermore, if you have committed Gemfile.lock to the repo, and your runtime system is not Linux, don’t forget to update the platform list in the lock file:    $ bundle lock --add-platform x86_64-linux      After the above steps, rename your repository to &amp;lt;GH_USERNAME&amp;gt;.github.io on GitHub.Now publish your Jekyll site by:      Push any commit to remote to trigger the GitHub Actions workflow. Once the build is complete and successful, a new remote branch named gh-pages will appear to store the built site files.        Browse to your repository on GitHub. Select the tab Settings, then click Pages in the left navigation bar, and then in the section Source of GitHub Pages, select the /(root) directory of branch gh-pages as the publishing source. Remember to click Save before leaving.            Visit your website at the address indicated by GitHub.  Manually Build and DeployOn self-hosted servers, you cannot enjoy the convenience of GitHub Actions. Therefore, you should build the site on your local machine and then upload the site files to the server.Go to the root of the source project, and build your site as follows:$ JEKYLL_ENV=production bundle exec jekyll bOr build the site on Docker:$ docker run -it --rm \\    --env JEKYLL_ENV=production \\    --volume=&quot;$PWD:/srv/jekyll&quot; \\    jekyll/jekyll \\    jekyll buildUnless you specified the output path, the generated site files will be placed in folder _site of the project’s root directory. Now you should upload those files to the target server.UpgradingIt depends on how you use the theme:      If you are using the theme gem (there will be gem &quot;jekyll-theme-chirpy&quot; in the Gemfile), editing the Gemfile and update the version number of the theme gem, for example:    - gem &quot;jekyll-theme-chirpy&quot;, &quot;~&amp;gt; 3.2&quot;, &quot;&amp;gt;= 3.2.1&quot;+ gem &quot;jekyll-theme-chirpy&quot;, &quot;~&amp;gt; 3.3&quot;, &quot;&amp;gt;= 3.3.0&quot;        And then execute the following command:    $ bundle update jekyll-theme-chirpy        As the version upgrades, the critical files (for details, see the Startup Template) and configuration options will change. Please refer to the Upgrade Guide to keep your repo’s files in sync with the latest version of the theme.        If you forked from the source project (there will be gemspec in the Gemfile of your site), then merge the latest upstream tags into your Jekyll site to complete the upgrade.The merge is likely to conflict with your local modifications. Please be patient and careful to resolve these conflicts.  "
  },
  
  {
    "title": "How to build you apis",
    "url": "/posts/how-to-build-api/",
    "categories": "api",
    "tags": "api",
    "date": "2017-11-12 00:00:00 +0800",
    





    "snippet": "如何构建自己的api，即不臃肿，也不让人讨厌！1  : 数据构建快速构建安全可用的基础数据，fork data，保证 api 数据完整性！2  : 规划和创造端点端点理论:将操作计划转换为实际端点需要的功能(参照:REST-FULL API的理论和命名约定的最佳实践)API资源应该避免输出自增变量,而是唯一标识TDD[测试驱动开发（Test-Driven Development）]开发模式2.1 POST 和 PUT 的区别!PUT是在您事先知道整个URL并且操作是幂等的情况下使用的。(幂等性是一个很花哨的词，意思是“可以一遍又一遍地做而不会产生不同的结果”)复数、单数还是两者都有?( /user/1[用户1的信息]  /users[所有用户|1,2用户信息])一个谓词是一个操作,一个执行术语,我们的API只需要一个谓词—HTTP方法。所有其他动词都需要远离URL。名词是地方或事物。资源就是事物，而URL就是事物存在于互联网上的地方。( POST /users/5/messages HTTP/1.1 )2.2 常见的请求方式GET POST PUT PATCH DELETE COPY HEAD OPTIONS LINK UNLINK LOCK UNLOCK PROPFIND VIEW2.3 规划端点:控制器,路由Create POST /users Route::post(‘users’,’UsersController@create’);常见的REST-FULL API请求：Planning and Creating Endpoints，规划 和 创造 端点(url访问路径)分析功能需求，映射成单一的功能模块简单的功能需求[增删改查,列表]): 创建, 读取, 更新, 删除, 列表class Chapter02{    //获取资源(功能点)    //•获取/资源——特定数据的分页列表，以某种逻辑默认顺序。    //•GET /resources/X -实体X，它可以是ID、散列、段塞、用户名等，只要它是唯一的一个“资源”。    public function resourceGet()    {    }    //删除资源(功能点)    //•删除/位置/X -删除单个位置。    //•删除/位置/X,Y,Z -删除一些位置。    //•删除/位置-这是一个潜在的危险端点，可以跳过，因为它应该删除所有位置。    //•删除/位置/X/图像-删除一个位置的图像，或:    //•删除/位置/X/图像-如果你选择多个图像，这将删除所有的图像。    public function resourceDel()    {    }}3  : 输入输出使用 PHP 和 Guzzle HTTP 库发出HTTP请求GraphQL(所见即所得) 和 REST Ful API 的差异1.请求:  POST /try.php HTTP/1.1  Host: localhost:20002  Content-Type: application/json  Cache-Control: no-cache  Postman-Token: 2d7cca56-c0a4-ea21-68ad-0aa6e3482da8  {“query”: “query { echo(message: &quot;Hello World 111&quot;) }” }2.响应:  HTTP/1.1 200 OK  Date: Fri, 04 Jan 2019 07:33:38 GMT  Content-Type: application/json; charset=utf-8  Transfer-Encoding: chunked  Server: localhost:20002  Status: 200 OK  {“code”:”200”,”data”:”test”}3.格式:  Content-Type: application/x-www-form-urlencoded  Content-Type: multipart/form-data; …  js: $(selector).serializeArray() 将匹配的元素转成json字符串  多维数组拼接: arr[test]=1&amp;amp;arr[name]=name4.JSON 和 XML(不易于存储,文件较大,一切都为字符串[整数,布尔,null可能会混淆])5.内容结构：Json Api (优点:响应一致,结构相同|缺点:无法多响应)/**输入输出理论(HTTP请求和响应) * Class Chapter3 * @package bookLog\\buildApis */class Chapter03{    //GraphQL    //get /compareGraphUsers    /*{     user(id: &quot;1&quot;) {        id        email        }    }*/  //获取用户1的id和email    public function compareGraphUsers()    {    }    //RESTFul    //get /compareRestFulUsers/1 (获取用户1的信息)    public function compareRestFulUsers()    {    }    //(new Chapter03())-&amp;gt;test(function(){return 11;});    public function test(?callable $function)    {        $a = $function();        return $a ;    }    //Json Api 名称空间    public function nameSpace5()    {        $json = &#39;{&quot;name&quot;:&quot;Tome&quot;,&quot;age&quot;:&quot;17&quot;}&#39;;        $jsonNameSpace = &#39;{&quot;data&quot;:[{            &quot;name&quot;:&quot;Tome&quot;,&quot;age&quot;:&quot;17&quot;        }]}&#39;;    }}4  : 状态码,错误,信息1.HTTP状态代码、自定义错误代码和消息2.HTTP状态码  1xx是消息响应,服务器收到请求,需要请求者继续执行操作  2xx是关于成功的(在发送响应之前，客户机尝试做的任何事情都是成功的。请记住，像202 accept这样的状态并不表示实际结果，它只表示接受了一个请求并正在异步处理。)  3xx是关于重定向的(这些都是关于将调用应用程序发送到实际资源的其他地方。其中最著名的是303 See Other和301永久移动，web上经常使用它们将浏览器重定向到另一个URL。)  4xx是关于客户端错误的  5xx是关于服务器的3.错误代码和错误消息   以编程的方式去检查错误代码(测试脚本)4.错误或者更多错误   (通常情况下,在验证的时候,有一个错误后就会终止控制器)   (一次性验证所有的信息,若有错就返回所有的错误信息)5.错误响应标准  Json Api: https://jsonapi.org  RFC : https://tools.ietf.org/html/draft-nottingham-http-problem-07  Crell/ApiProblem PHP: https://github.com/Crell/ApiProblem6.常见的陷阱200 有错误信息 ×/** 状态码,错误,信息 * Class Chapter04 * @package bookLog\\buildApis */class Chapter04{    /** 单个错误提示     * @return string     */    public function errorOne()    {        $backData = [            &#39;code&#39; =&amp;gt; &#39;400&#39; ,            &#39;messages&#39;=&amp;gt;&#39;操作错误!&#39;,            &#39;errors&#39;=&amp;gt;[],        ] ;        return json_encode($backData,true);    }    /** 多个错误提示     * @return string     */    public function errorMore()    {        $backData = [            &quot;errors&quot; =&amp;gt; [                [                    &#39;code&#39;=&amp;gt;&#39;400&#39;,                    &#39;messages&#39;=&amp;gt;&#39;操作错误!&#39;,                ],                [                    &#39;code&#39;=&amp;gt;&#39;403&#39;,                    &#39;messages&#39;=&amp;gt;&#39;无操作权限!&#39;,                ]            ]        ];        return json_encode($backData,true);    }    /** Json API 返回格式     * @return string     */    public function errorJsonApi()    {        //错误 : [{ 代码,标题,详细信息,问题的更多细节 }]        $json = &#39;{        &quot;errors&quot;:            [{            &quot;code&quot;: &quot;ERR-01234&quot;,            &quot;title&quot;: &quot;OAuth Exception&quot;,            &quot;details&quot;: &quot;Session has expired at unix time 1385243766. The current unix time is 1385848532.&quot;,            &quot;href&quot;: &quot;http://example.com/docs/errors/#ERR-01234&quot;            }]        }&#39;;        return $json ;    }}5  : 端点测试1.介绍API测试2.概念和工具  对于API，有一些东西需要测试，但最基本的思想是，“当我请求这个URL时，我想看到一个foo资源”，“当我向API抛出一个JSON时，它应该接受它或拒绝它。”TDD(测试驱动开发):  API接口测试,如果有很多接口,那么测试代码就会越写越多,一处报错整体无法运行 phpunitBDD(行为驱动开发) :  cucumber(ruby) : https://cucumber.io/  behat(php) : http://docs.behat.org/en/latest/行为驱动开发（BDD）采取的立场是:  您可以简单有效地将需求的想法转变为实施，测试，生产就绪的代码，只要要求足够具体，每个人都知道发生了什么。  要做到这一点，我们需要一种方法来描述需求，以便每个人 - 业务人员，分析师，开发人员和测试人员 - 对工作范围有共同的理解。  由此他们可以达成共同的“完成”定义，并且我们摆脱了“那不是我要求的”或“我忘了告诉你关于其他事情” 的双重陷阱。3.安装(behat)composer require --dev behat/behat./vendor/bin/behat -V  查看当前版本4.初始化./vendor/bin/behat --init (会自动生成框架所需文件=&amp;gt;features\\bootstrap\\)5.特性(编码)，在features\\bootstrap\\FeatureContext.php中进行API测试编写            Action      Endpoint      Feature                  Create      POST      /users features/users.feature              Read      GET      /users/X features/users.feature              Update      PUT      /users/X features/users.feature              Delete      DELETE      /users/X features/users.feature              List      GET      /users features/users.feature              Image      PUT      /users/X/image features/users-image.feature              Favorites      GET      /users/X/favorites features/users-favorites.feature              Checkins      GET      /users/X/checkins features/users-checkins.feature      6.示例  Endpoint Testing (测试):  Feature: Places  Scenario: Finding a specific place       When I request &quot;GET /places/1&quot;       Then I get a &quot;200&quot; response       And scope into the &quot;data&quot; property           And the properties exist:               &quot;&quot;&quot;               id               name               lat               lon               address1               address2               city               state               zip               website               phone               &quot;&quot;&quot;           And the &quot;id&quot; property is an integer  Scenario: Listing all places is not possible       When I request &quot;GET /places&quot;       Then I get a &quot;400&quot; response  Scenario: Searching non-existent places       When I request &quot;GET /places?q=c800e42c377881f8ae509cf9a516d4eb59&amp;amp;lat=1&amp;amp;lon=1&quot;       Then I get a &quot;200&quot; response       And the &quot;data&quot; property contains 0 items  Scenario: Searching places with filters       When I request &quot;GET /places?lat=40.76855&amp;amp;lon=-73.9945&amp;amp;q=cheese&quot;       Then I get a &quot;200&quot; response       And the &quot;pagination&quot; property is an object       And the &quot;data&quot; property is an array       And scope into the first &quot;data&quot; property           And the properties exist:               &quot;&quot;&quot;               id               name               lat               lon               address1               address2               city               state               zip               website               phone               &quot;&quot;&quot;           And reset scope7.编写behat8.运行behat./vendor/bin/behat9.其他/ ** … * /是PHP中的一种称为doc-block的特殊语法。它在运行时可被发现，并被不同的PHP框架用作为类，方法和函数提供附加元信息的方法。Behat使用doc-blocks进行步骤定义，步骤转换和钩子。首先，像Behat这样的工具实际上关闭了故事的沟通循环。这意味着不仅您和您的利益相关者可以共同定义您的功能在实现之前应该如何工作，BDD工具允许您在实现此功能后自动执行该行为检查。所以每个人都知道什么时候完成以及团队何时可以停止编写代码。从本质上讲，这就是Behat。6  : 输出数据1.介绍：输出数据2.直接法：每个开发人员要做的第一件事就是使用他们最喜欢的ORM(对象关系映射)、ODM、DataMapper或Query Builder，调出一个查询，然后将结果直接导入输出。  性能(获取所有数据时,数据过大)  显示(格式都为json)  安全性(非必要字段)  稳定性(v1、v2、v3，不同版本号)3.分形变换简单的API数据可以用json_encode,复杂多变的数据json_encode输出类型可能改变,提供一个单独的API输出方法或者类http://fractal.thephpleague.com/https://marshmallow.readthedocs.io/en/3.0/4.隐藏模式更新‘website’ =&amp;gt; $data-&amp;gt;website  update  ‘website’ =&amp;gt; $data-&amp;gt;url5.输出错误API: 400 ,404 ,4036.测试输出(有效输出)7  : 数据关系1.介绍  API输出的关系不需要直接映射到数据库关系。  如果正确地构建了数据库关系，那么关系通常是相似的，但是输出可能具有额外的动态关系，这些关系不是由连接定义的，而且不一定包含所有可能的数据库关系。  REST组件:https://www.ics.uci.edu/~fielding/pubs/dissertation/rest_arch_style.htm#sec_5_22.子资源  Station: 一个区域有50个地点  Get place/x/info  info(地点,经纬度,图像,相关信息,[这里假设是4个请求])请求数: 1 + (50×4) = 251 ;请求太过频繁  Get places 一个请求获取所有的数据,数据量太大,对客户端不友好.  Get places/main 获取地点的主要信息(图像) 点击时获取其他信息 Get place/x/info  这里的权衡是，下载足够的数据以避免用户等待后续加载和下载太多数据以使他们等待初始加载是困难的。API需要这种灵活性，而将子资源作为加载相关数据的唯一方式对于API使用者来说是有限制的。3.外键数组   {       &quot;post&quot;: {           &quot;id&quot;: 1,           &quot;title&quot;: &quot;Progressive Enhancement is Dead&quot;,           &quot;_links&quot;: {                       &quot;comments&quot;: [&quot;1&quot;, &quot;2&quot;]                     }           }   }  使用 _links作为外键数组,即有数据的时候需要再次请求  Get comments/1  Get comments/2  或 Get comments/1,2  变向的减少了http并发请求，缺点是API使用者必须将所有这些数据连接在一起，这对于大型数据集来说可能需要大量的工作。4.复合文件(边读)：也是需要做大量的拼接和映射参考地址： https://canvas.instructure.com/doc/api/file.compound_documents.html获取作者有那些文章{    &quot;posts&quot;: [                {                    &quot;id&quot;: &quot;1&quot;,                    &quot;title&quot;: &quot;Awesome API Book&quot;,                    &quot;_links&quot;: { &quot;comments&quot;: [&quot;1&quot;,&quot;2&quot;] }                },                {                    &quot;id&quot;: &quot;2&quot;,                    &quot;title&quot;: &quot;But Really That API Book&quot;,                    &quot;_links&quot;: { &quot;comments&quot;: [&quot;3&quot;] }                }            ],    &quot;_linked&quot;: {        &quot;comments&quot;: [                {                    &quot;id&quot;: &quot;1&quot;,                    &quot;message&quot;: &quot;Great book&quot;,                    &quot;created_at&quot;: &quot;2014-08-23T18:20:03Z&quot;                },                {                    &quot;id&quot;: &quot;2&quot;,                    &quot;message&quot;: &quot;I lolled&quot;,                    &quot;created_at&quot;: &quot;2014-08-24T20:04:01Z&quot;                },                {                    &quot;id&quot;: &quot;3&quot;,                    &quot;message&quot;: &quot;Ugh JSON-API...&quot;,                    &quot;created_at&quot;: &quot;2014-08-29T14:01:13Z&quot;                }            ]    }}5.嵌入式文档(嵌套)Get place?include=img,merchant,check{    &quot;data&quot;: [        {            &quot;id&quot;: 2,            &quot;name&quot;: &quot;Videology&quot;,            &quot;lat&quot;: 40.713857,            &quot;lon&quot;: -73.961936,            &quot;created_at&quot;: &quot;2013-04-02&quot;,            &quot;check&quot;: [],            &quot;merchant&quot;: [],            &quot;img&quot;: []        }    ]}用Rails嵌入 (将公用信息提取出来,进行分层){    &quot;id&quot;: 1,    &quot;name&quot;: &quot;Konata Izumi&quot;,    &quot;age&quot;: 16,    &quot;created_at&quot;: &quot;2006/08/01&quot;,    &quot;awesome&quot;: true,    &quot;posts&quot;: [        {            &quot;id&quot;: 1,            &quot;author_id&quot;: 1,            &quot;title&quot;: &quot;Welcome to the weblog&quot;        },        {            &quot;id&quot;: 2,            &quot;author_id&quot;: 1,            &quot;title&quot;: &quot;So I was thinking&quot;        }    ]}6.总结：根据业务数据进行分析http://fractal.thephpleague.com/serializers/8  : 调试1.介绍命令行调试,浏览器调试,网络调试一般来说调试为 发送请求(请求参数,请求体,报文,浏览器信息等等),接收响应(响应数据,响应格式,响应体等等)2.命令行调试,发送curl请求3.浏览器调试HTTP客户端(postman) : @link https://www.getpostman.com/调试面板  发条: https://github.com/itsgoingd/clockwork-chrome (php)  Chrome Logger : https://craig.is/writing/chrome-logger (多平台)  tampermonkey : https://tampermonkey.net/  (chrome 脚本控制)  Chrome Logger(PHP版)使用4.网络调试(工具调试)  Charles : https://www.charlesproxy.com/ (windows)  Wireshark : https://www.wireshark.org/ (Linux/OS/windows)  本地和远程 (可配置的调试)9  : 身份验证1.介绍使用带有cookie、Memcache、Redis、Mongo或某些SQL平台等数据存储的会话被广泛接受为标准行为。2.什么时候验证只读api(不需要认证的),一般情况下提供一个账号给调用者使用,方便控制恶意请求,恶意数据,内部API(运行在内部环境,或者局域网中的),可以跳过身份认证3.不同的身份认证方法3.1 SSL(Secure Sockets Layer 安全套接层),及其继任者传输层安全（Transport Layer Security，TLS）是为网络通信提供安全及数据完整性的一种安全协议3.2 HTTP Basic :  HTTP基本身份验证(BA)实现是对web资源实施访问控制的最简单技术，因为它不需要cookie、会话标识符和登录页面。  相反，HTTP基本身份验证使用静态的标准HTTP报头，这意味着不需要预先握手。 ——来源:维基百科  (易实现,易理解,工作在浏览器和任何其他HTTP客户端)(HTTP上非常不安全,HTTPS相当不安全,密码由浏览器保存不安全)3.3 摘要身份认证: 摘要是一种类似于Basic的身份验证方法，但旨在改进安全性问题。3.4 OAuth 1.0 |1.0a (OAuth Token and OAuth Token Secret) : 无法轻松访问浏览器的移动和桌面应用程序设计  POST/moments/1/giftHTTP/1.1Host: api.example.comAuthorization: OAuthrealm=&quot;http://sp.example.com/&quot;,oauth_consumer_key=&quot;0685bd9184jfhq22&quot;,oauth_token=&quot;ad180jjd733klru7&quot;,oauth_signature_method=&quot;HMAC-SHA1&quot;,oauth_signature=&quot;wOJIO9A2W5mFwDgiDvZbTSMK%2FPY%3D&quot;,oauth_timestamp=&quot;137131200&quot;,oauth_nonce=&quot;4572616e48616d6d65724c61686176&quot;,oauth_version=&quot;1.0&quot;11Content-Type: application/json1213{  &quot;user_id&quot;: 2 }  3.5 OAuth 2.0 : 删除了秘密令牌,只需获得一个访问令牌。  POST /moments/1/gift HTTP/1.1Host: api.example.comAuthorization: Bearer vr5HmMkzlxKE70W1y4MiContent-Type: application/json{ &quot;user_id&quot; : 2 }无论何时，您都应该尝试使用授权头来发送令牌。生命令牌(任意一段时间后过期)Grant Types其他认证:    OpenId : https://openid.net/    Hawk   : https://github.com/hueniverse/hawk    Oz     : https://github.com/hueniverse/oz  4.实现OAuth 2.0服务器http://oauth2.thephpleague.com/installation/http://bshaffer.github.io/oauth2-server-php-docs/5.其他服务器OAuth 2.0 (Ruby,python,rack,…)6.理解OAuth 2.0 授权类型 授权代码 : (多站点共享登录) =&amp;gt; (规范)    https://tools.ietf.org/html/rfc6749#section-4.1 刷新令牌 : 一直使用相同的令牌可能会被破解 https://tools.ietf.org/html/rfc6749#section-6 客户端凭证 : 我是一个应用程序,你知道我是一个应用程序,             因为这是我的client_id和client_secret值 . 认证过后,请让我通行!             http://tools.ietf.org/html/rfc6749 密码(用户凭证) : 用户凭据可能是为用户获取访问令牌的最简单方法。                 这就跳过了“身份验证代码”提供的整个重定向流，以及随之而来的用户心态平和，但确实提供了简单性。                 https://tools.ietf.org/html/rfc6749#section-4.3 自定义授权类型 :  access_token                 eg : 登录                     获取用户的数据                     找出他们是否是一个系统用户，如果不是，创建一个系统用户记录                     创建访问令牌、刷新令牌等，以给予该用户访问权class Chapter09{    public function HttpBasic()    {        //$data = &quot;eyJ2ZXJzaW9uIjoiNC4xLjAiLCJjb2x1bW5zIjpbImxvZyIsImJhY2t0cmFjZSIsInR5cGUiXSwicm93cyI6W1tbMjNdLCJEOlxcTWluXFxJbnN0YWxsXFxwaHBzdHVkeVxcUEhQVHV0b3JpYWxcXFdXV1xcU2VsZlxcTXlPYmpTdW1tYXJ5XFx0cnkucGhwIDogNSIsIiJdLFtbeyJET0NVTUVOVF9ST09UIjoiRDpcXE1pblxcSW5zdGFsbFxccGhwc3R1ZHlcXFBIUFR1dG9yaWFsXFxXV1dcXFNlbGZcXE15T2JqU3VtbWFyeSIsIlJFTU9URV9BRERSIjoiOjoxIiwiUkVNT1RFX1BPUlQiOiI2MTAxOSIsIlNFUlZFUl9TT0ZUV0FSRSI6IlBIUCA3LjEuMTMgRGV2ZWxvcG1lbnQgU2VydmVyIiwiU0VSVkVSX1BST1RPQ09MIjoiSFRUUFwvMS4xIiwiU0VSVkVSX05BTUUiOiJsb2NhbGhvc3QiLCJTRVJWRVJfUE9SVCI6IjIwMDAyIiwiUkVRVUVTVF9VUkkiOiJcL3RyeS5waHAiLCJSRVFVRVNUX01FVEhPRCI6IkdFVCIsIlNDUklQVF9OQU1FIjoiXC90cnkucGhwIiwiU0NSSVBUX0ZJTEVOQU1FIjoiRDpcXE1pblxcSW5zdGFsbFxccGhwc3R1ZHlcXFBIUFR1dG9yaWFsXFxXV1dcXFNlbGZcXE15T2JqU3VtbWFyeVxcdHJ5LnBocCIsIlBIUF9TRUxGIjoiXC90cnkucGhwIiwiSFRUUF9IT1NUIjoibG9jYWxob3N0OjIwMDAyIiwiSFRUUF9DT05ORUNUSU9OIjoia2VlcC1hbGl2ZSIsIkhUVFBfUFJBR01BIjoibm8tY2FjaGUiLCJIVFRQX0NBQ0hFX0NPTlRST0wiOiJuby1jYWNoZSIsIkhUVFBfVVBHUkFERV9JTlNFQ1VSRV9SRVFVRVNUUyI6IjEiLCJIVFRQX1VTRVJfQUdFTlQiOiJNb3ppbGxhXC81LjAgKFdpbmRvd3MgTlQgMTAuMDsgV09XNjQpIEFwcGxlV2ViS2l0XC81MzcuMzYgKEtIVE1MLCBsaWtlIEdlY2tvKSBDaHJvbWVcLzY2LjAuMzM1OS4xMzkgU2FmYXJpXC81MzcuMzYiLCJIVFRQX0FDQ0VQVCI6InRleHRcL2h0bWwsYXBwbGljYXRpb25cL3hodG1sK3htbCxhcHBsaWNhdGlvblwveG1sO3E9MC45LGltYWdlXC93ZWJwLGltYWdlXC9hcG5nLCpcLyo7cT0wLjgiLCJIVFRQX0FDQ0VQVF9FTkNPRElORyI6Imd6aXAsIGRlZmxhdGUsIGJyIiwiSFRUUF9BQ0NFUFRfTEFOR1VBR0UiOiJ6aC1DTix6aDtxPTAuOSIsIlJFUVVFU1RfVElNRV9GTE9BVCI6MTU0NzE3MzM5MS4xNDQyMzgsIlJFUVVFU1RfVElNRSI6MTU0NzE3MzM5MX1dLCJEOlxcTWluXFxJbnN0YWxsXFxwaHBzdHVkeVxcUEhQVHV0b3JpYWxcXFdXV1xcU2VsZlxcTXlPYmpTdW1tYXJ5XFx0cnkucGhwIDogNiIsImluZm8iXV0sInJlcXVlc3RfdXJpIjoiXC90cnkucGhwIn0=&quot;;        //$a = json_decode(utf8_decode(base64_decode($data)));        //dd($a);        //base64_encode(utf8_encode(json_encode($data)));       //dd(base64_encode(&#39;test:111&#39;));       //request header        /*POST /try.php HTTP/1.1        Host: localhost:20002        Authorization: Basic dGVzdDoxMTE=  ( Basic认证方式[Digest,AWS,...]  dGVzdDoxMTE=认证auth )        Cache-Control: no-cache        Postman-Token: 15e7429a-5d84-1246-6d2a-f60bc060c01b*/       $basic = $_SERVER[&#39;HTTP_AUTHORIZATION&#39;] ?? &#39;&#39; ; //  Basic dGVzdDoxMTE=       $basicArr = explode(&quot; &quot;,$basic) ; // [&#39;Basic&#39;,&#39;dGVzdDoxMTE=&#39;]       switch ($basicArr[0]){           case &#39;Basic&#39;:               return  base64_decode($basicArr[1]); // test:111           default :               return $basic;       }    }}10 : 分页1.为了限制HTTP响应大小，可以将数据分成多个HTTP请求。下载更多的东西需要更长的时间,您的数据库可能不喜欢尝试一次返回100,000条记录迭代超过100,000条记录的表示逻辑并不有趣,API可以有端点 100,000 可以是任意数字,(定义一个最大值)2.Paginators(laravel 分页器){    &quot;data&quot;: [    &quot;...&quot;],    &quot;pagination&quot;: {    &quot;total&quot;: 1000,        &quot;count&quot;: 12,        &quot;per_page&quot;: 12,        &quot;current_page&quot;: 1,        &quot;total_pages&quot;: 84,        &quot;next_url&quot;: &quot;/places?page=2&amp;amp;number=12&quot;    }}3.偏移量和游标游标通常是唯一标识符或偏移量，因此API只能请求更多数据。使用偏移量很简单。不管您的id是什么—自动递增的，UUID等等—您只需在其中输入12，          然后说“我想要12条记录，偏移量为12”，而不是说“我想要id=12之后的记录”。模糊游标: 加密ID . eg: base64_encode(1) // MQ==额外请求 = 悲伤 : 一些客户端开发人员不喜欢这种方法，因为他们不喜欢必须发出额外的HTTP请求才能发现没有数据的想法。使用链接头分页   &amp;lt;https://api.github.com/user/repos?page=3&amp;amp;per_page=100&amp;gt;; rel=&quot;next&quot;   &amp;lt;https://api.github.com/user/repos?page=50&amp;amp;per_page=100&amp;gt;; rel=&quot;last&quot;11 : 文档phpDocument : https://phpdoc.org/soundCloudApi : http://developers.soundcloud.com/docs/api/guideSculpin : https://sculpin.io/ 是一个用PHP编写的静态站点生成器。它将Markdown文件，Twig模板和标准HTML转换为可轻松部署的静态HTML站点。Swagger定义了一个规范，各种语言或框架特定于spe的实现都有自己的解决方案。对于PHP，实现这一点的方法是通过一组相当混乱(且文档很少)的带有奇怪名称的注释。此外，它要求您将这些注释分布到应用程序的一大块区域，包括您可能甚至没有的数据映射器样式模型。它需要属性级注释，而我的模型和分形转换器都没有属性，所以这是一种疯狂而古怪的尝试和工作方式。https://swagger.io/            Apiary API Blueprint : https://apiary.io/blueprint      https://apiary.io/ (本书推荐)      12 : HATEOAS(超媒体控制)1.介绍HATEOAS : 它代表作为应用程序状态引擎的超媒体，被宣布为hat-ee-os、hate O-A-S或hate-ee-ohs;            包括 : 内容协商 , 超媒体控制            更改Accept标头并在响应中将内容类型标头从JSON切换到XML或CSV非常好，而且非常容易做到。2.内容协商 /status/show.json?id=123  ×   json格式 /status/show.xml?id=123   ×   xml格式上面API有点滥用资源概念/status/123     √ : 这样做的双重好处是，允许API使用默认的内容类型进行响应，或者尊重Accept头并输出请求内容类型，或者在API不支持的情况下输出415状态代码。  大多数流行API默认情况下都支持 JSON ,除此之外还有 Xml ,YAml(https://symfony.com/doc/current/components/yaml.html) 等等 .  URI = Universal Resource Identifier 统一资源标志符  URL = Universal Resource Locator 统一资源定位符  URN = Universal Resource Name 统一资源名称  URI = ( URL or URN or (URL and URN))3.超媒体控制 : 它们只是指向其他内容、关系和进一步操作的链接。超媒体的基本主题是API应该能够对API客户机应用程序和人的外观产生完美的意义 .缩写“URI”通常用于仅指协议、主机名和端口之后的内容(意味着URI是路径、扩展名和查询字符串)，而“URL”用于描述完整地址。rel 代表关系,uri 通用资源指定器{    &quot;data&quot;: [        &quot;id&quot;: 1,        &quot;name&quot;: &quot;Mireille Rodriguez&quot;,        &quot;links&quot;: [            {                &quot;rel&quot;: &quot;self&quot;,                &quot;uri&quot;: &quot;/places/2&quot;            },            {                &quot;rel&quot;: &quot;place.checkins&quot;,                &quot;uri&quot;: &quot;/places/2/checkins&quot;            },            {                &quot;rel&quot;: &quot;place.image&quot;,                &quot;uri&quot;: &quot;/places/2/image&quot;            }        ]    ]}13 : 版本控制1.介绍你会发现大多数专家给出的一般建议是:尽量限制变化。这是一个非常公平的声明，但似乎有点逃避。无论您的API规划得多么好，您的业务需求最终都可能迫使您做出重大更改。2.不同API的版本控制 URI : 在URI中抛出版本号是流行的公共api中非常常见的做法。 /v1/places   /v2/places       根据业务 v1 v2可以对应不同的代码,服务器,甚至是编程语言 Hostname : http://api-v1.com/places  http://api-v2.com/places Body And Query Params(主体和查询参数) :     POST /places HTTP/1.1     Host: api.example.com     Content-Type: application/json     {   &quot;version&quot; : &quot;1.0&quot;  } (自定义版本参数) 自定义请求头 :     Request :         GET /places HTTP/1.1         Host: api.example.com         BadApiVersion: 1.0  (自定义header头)     Response :         HTTP/1.1 200 OK         BadAPIVersion: 1.1         Vary: BadAPIVersion 内容协商 :         application/vnd.github[.version].param[+json]         eg:             Accept: application/vnd.github.v3+json|xml|yaml|... 资源的内容协商 :          application/vnd.github[.version].param[+json] ; version=1.0          Accept: application/vnd.github.user.v4+json          Accept: application/vnd.github.user+json; version=4.0 特性标记 :3.询问用户来源  Build APIs You Won’t Hate"
  },
  
  {
    "title": "高内聚低耦合",
    "url": "/posts/hight-low-design/",
    "categories": "Design",
    "tags": "",
    "date": "2017-03-15 00:00:00 +0800",
    





    "snippet": "模块之间存在依赖， 导致改动可能会互相影响， 关系越紧密， 耦合越强， 模块独立性越差。模块内部的元素，关联性越强， 则内聚越高， 模块单一性更强。模块模块就是从逻辑上将系统分解为更细微的部分， 分而治之， 复杂问题拆解为若干简单问题， 逐个解决。耦合主要描述模块之间的关系， 内聚主要描述模块内部。 模块的粒度可大可小， 可以是函数， 类， 功能块等等。耦合模块之间存在依赖， 导致改动可能会互相影响， 关系越紧密， 耦合越强， 模块独立性越差。比如模块A直接操作了模块B中数据， 则视为强耦合， 若A只是通过数据与模块B交互， 则视为弱耦合。独立的模块便于扩展， 维护， 写单元测试， 如果模块之间重重依赖， 会极大降低开发效率。内聚模块内部的元素， 关联性越强， 则内聚越高， 模块单一性更强。 一个模块应当尽可能独立完成某个功能，如果有各种场景需要被引入到当前模块， 代码质量将变得非常脆弱， 这种情况建议拆分为多个模块。低内聚的模块代码， 不管是维护， 扩展还是重构都相当麻烦， 难以下手。接口设计原则好的接口应当满足设计模式六大原则， 很多设计模式， 框架都是基于高内聚低耦合这个出发点的。  单一职责原则：一个类只负责一个功能领域中的相应职责。  开闭原则：一个软件实体应当对扩展开放，对修改关闭。  里氏代换原则：所有引用基类（父类）的地方必须能透明地使用其子类的对象。  依赖倒转原则：抽象不应该依赖于细节， 细节应当依赖于抽象。 换言之， 要针对接口编程， 而不是针对实现编程。  接口隔离原则：使用多个专门的接口， 而不使用单一的总接口， 即客户端不应该依赖那些它不需要的接口。  迪米特法则： 一个软件实体应当尽可能少地与其他实体发生相互作用， 例如外观模式， 对外暴露统一接口。举几个栗子外观模式为系统中多个子系统提供一致的对外调用， 对客户端隐藏子系统细节， 降低其与子系统的耦合。桥接模式JDBC中的把面向厂商的接口(Driver)和面向使用者的API(DriverManager)做了拆分隔离。适配器模式引入第三方库(hibernate， log4j)， 不应该直接在代码中继承或者使用其实体类。需要抽出上层统一接口， 然后增加实现类， 对外暴露接口。来源作者：大道方圆 Link"
  }
  
]

